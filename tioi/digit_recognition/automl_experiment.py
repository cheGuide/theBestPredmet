"""
AutoML —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ü–∏—Ñ—Ä –∏–∑ –∞—É–¥–∏–æ
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç Auto-Keras –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
–ò MLflow –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
"""

import os
import numpy as np
import matplotlib.pyplot as plt
import mlflow
import mlflow.tensorflow
import autokeras as ak
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
from datetime import datetime
import json

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
IMG_SIZE = (224, 224)
BATCH_SIZE = 8
MAX_TRIALS = 5  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä –¥–ª—è AutoML
EPOCHS = 10

# –ü—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º
train_dir = "spectrogram_dataset/train"
val_dir = "spectrogram_dataset/val"

def setup_mlflow():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ MLflow —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞"""
    experiment_name = "Digit_Recognition_AutoML"
    
    try:
        experiment_id = mlflow.create_experiment(experiment_name)
    except:
        experiment = mlflow.get_experiment_by_name(experiment_name)
        experiment_id = experiment.experiment_id
    
    mlflow.set_experiment(experiment_name)
    return experiment_id

def prepare_data():
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è AutoML"""
    print("üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ...")
    
    train_gen = ImageDataGenerator(
        rescale=1./255,
        rotation_range=10,
        width_shift_range=0.1,
        height_shift_range=0.1,
        horizontal_flip=False
    ).flow_from_directory(
        train_dir, 
        target_size=IMG_SIZE, 
        batch_size=BATCH_SIZE, 
        class_mode='categorical',
        shuffle=True
    )
    
    val_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(
        val_dir, 
        target_size=IMG_SIZE, 
        batch_size=BATCH_SIZE, 
        class_mode='categorical',
        shuffle=False
    )
    
    return train_gen, val_gen

def run_automl_experiment():
    """–ó–∞–ø—É—Å–∫ AutoML —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ —Å MLflow tracking"""
    
    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º MLflow
    experiment_id = setup_mlflow()
    
    with mlflow.start_run(run_name=f"AutoML_Run_{datetime.now().strftime('%Y%m%d_%H%M%S')}"):
        
        # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
        mlflow.log_param("max_trials", MAX_TRIALS)
        mlflow.log_param("epochs", EPOCHS)
        mlflow.log_param("batch_size", BATCH_SIZE)
        mlflow.log_param("img_size", IMG_SIZE)
        mlflow.log_param("automl_type", "ImageClassifier")
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        train_gen, val_gen = prepare_data()
        
        print(f"üìä –ù–∞–π–¥–µ–Ω–æ –∫–ª–∞—Å—Å–æ–≤: {train_gen.num_classes}")
        print(f"üî¢ –û–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤: {train_gen.samples}")
        print(f"üéØ –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤: {val_gen.samples}")
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞–Ω–Ω—ã—Ö
        mlflow.log_param("num_classes", train_gen.num_classes)
        mlflow.log_param("train_samples", train_gen.samples)
        mlflow.log_param("val_samples", val_gen.samples)
        mlflow.log_param("class_names", list(train_gen.class_indices.keys()))
        
        # –°–æ–∑–¥–∞—ë–º AutoML –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
        print("ü§ñ –ó–∞–ø—É—Å–∫–∞–µ–º AutoML –ø–æ–∏—Å–∫ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã...")
        
        clf = ak.ImageClassifier(
            max_trials=MAX_TRIALS,
            overwrite=True,
            project_name="digit_recognition_automl"
        )
        
        # –û–±—É—á–∞–µ–º AutoML –º–æ–¥–µ–ª—å
        history = clf.fit(
            train_gen,
            validation_data=val_gen,
            epochs=EPOCHS,
            verbose=1
        )
        
        # –ü–æ–ª—É—á–∞–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
        best_model = clf.export_model()
        
        print("‚úÖ AutoML –æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        
        # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
        print("üìà –û—Ü–µ–Ω–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å...")
        
        val_loss, val_accuracy = best_model.evaluate(val_gen, verbose=0)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è confusion matrix
        val_gen.reset()
        predictions = best_model.predict(val_gen, verbose=0)
        y_pred = np.argmax(predictions, axis=1)
        y_true = val_gen.classes
        
        # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
        mlflow.log_metric("val_accuracy", val_accuracy)
        mlflow.log_metric("val_loss", val_loss)
        
        # Classification report
        class_names = list(val_gen.class_indices.keys())
        report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)
        
        # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø–æ –∫–ª–∞—Å—Å–∞–º
        for class_name in class_names:
            if class_name in report:
                mlflow.log_metric(f"precision_{class_name}", report[class_name]['precision'])
                mlflow.log_metric(f"recall_{class_name}", report[class_name]['recall'])
                mlflow.log_metric(f"f1_{class_name}", report[class_name]['f1-score'])
        
        # –û–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏
        mlflow.log_metric("macro_avg_f1", report['macro avg']['f1-score'])
        mlflow.log_metric("weighted_avg_f1", report['weighted avg']['f1-score'])
        
        # –°–æ–∑–¥–∞—ë–º confusion matrix
        cm = confusion_matrix(y_true, y_pred)
        
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                   xticklabels=class_names, yticklabels=class_names)
        plt.title('AutoML Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.tight_layout()
        plt.savefig("automl_confusion_matrix.png", dpi=150, bbox_inches='tight')
        plt.close()
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã
        mlflow.log_artifact("automl_confusion_matrix.png")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
        model_path = "automl_best_model"
        best_model.save(model_path)
        mlflow.tensorflow.log_model(best_model, "model")
        
        # –õ–æ–≥–∏—Ä—É–µ–º summary –º–æ–¥–µ–ª–∏
        with open("model_summary.txt", "w") as f:
            best_model.summary(print_fn=lambda x: f.write(x + '\n'))
        mlflow.log_artifact("model_summary.txt")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á—ë—Ç
        report_data = {
            "experiment_info": {
                "timestamp": datetime.now().isoformat(),
                "max_trials": MAX_TRIALS,
                "epochs": EPOCHS,
                "final_accuracy": float(val_accuracy),
                "final_loss": float(val_loss)
            },
            "classification_report": report,
            "confusion_matrix": cm.tolist(),
            "class_names": class_names
        }
        
        with open("automl_report.json", "w") as f:
            json.dump(report_data, f, indent=2)
        mlflow.log_artifact("automl_report.json")
        
        print(f"\nüéØ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã AutoML:")
        print(f"   –¢–æ—á–Ω–æ—Å—Ç—å: {val_accuracy:.4f}")
        print(f"   –ü–æ—Ç–µ—Ä–∏: {val_loss:.4f}")
        print(f"   –ú–∞–∫—Ä–æ F1: {report['macro avg']['f1-score']:.4f}")
        print(f"\nüìä –ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ MLflow")
        print(f"üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç–µ 'mlflow ui' –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        
        return best_model, val_accuracy, report

if __name__ == "__main__":
    print("ü§ñ –ó–∞–ø—É—Å–∫ AutoML —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ü–∏—Ñ—Ä")
    print("=" * 60)
    
    try:
        model, accuracy, report = run_automl_experiment()
        print(f"\n‚úÖ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –∑–∞–≤–µ—Ä—à—ë–Ω —É—Å–ø–µ—à–Ω–æ!")
        print(f"üèÜ –õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {accuracy:.4f}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–µ: {e}")
        print("üí° –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ spectrogram_dataset/") 