{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# üß† TIOI PZ1: –õ–æ–≥–∏—á–µ—Å–∫–∏–π –¥–≤–∏–∂–æ–∫ —Å –±–µ–Ω—á–º–∞—Ä–∫–∏–Ω–≥–æ–º\n",
        "\n",
        "–°–∏—Å—Ç–µ–º–∞ –ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –≤—ã–≤–æ–¥–∞ —Å –∞–Ω–∞–ª–∏–∑–æ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.\n",
        "\n",
        "**–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**\n",
        "- –û–±—Ä–∞–±–æ—Ç–∫–∞ –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∞–≤–∏–ª (AND, OR, NOT)\n",
        "- –ë–µ–Ω—á–º–∞—Ä–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
        "- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ (–≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫ vs sklearn)\n",
        "- –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## üì¶ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install matplotlib numpy scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°–æ–∑–¥–∞—ë–º —Ñ–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞\n",
        "import json\n",
        "\n",
        "# === rules.json ===\n",
        "rules_data = [\n",
        "    {\"if\": {\"or\": [1, 2]}, \"then\": 10},\n",
        "    {\"if\": {\"not\": [10, 11]}, \"then\": 15},\n",
        "    {\"if\": {\"not\": [15, 16]}, \"then\": 50}\n",
        "]\n",
        "\n",
        "with open('rules.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(rules_data, f, indent=2)\n",
        "\n",
        "# === facts.json ===\n",
        "facts_data = [1, 2]\n",
        "with open('facts.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(facts_data, f)\n",
        "\n",
        "print(\"‚úÖ –§–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞ —Å–æ–∑–¥–∞–Ω—ã!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–¥ –ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –¥–≤–∏–∂–∫–∞\n",
        "import random\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "def read_rules(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def read_facts(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def process_rules(rules, facts):\n",
        "    known_facts = set(facts)\n",
        "    new_facts = []\n",
        "    \n",
        "    for rule in rules:\n",
        "        if \"if\" not in rule or \"then\" not in rule:\n",
        "            continue\n",
        "        \n",
        "        condition = rule[\"if\"]\n",
        "        operator = list(condition.keys())[0]\n",
        "        values = set(condition[operator])\n",
        "        outcome = rule[\"then\"]\n",
        "        \n",
        "        if operator == \"and\" and values.issubset(known_facts):\n",
        "            new_facts.append(outcome)\n",
        "        elif operator == \"or\" and values.intersection(known_facts):\n",
        "            new_facts.append(outcome)\n",
        "        elif operator == \"not\" and not values.intersection(known_facts):\n",
        "            new_facts.append(outcome)\n",
        "    \n",
        "    known_facts.update(new_facts)\n",
        "    return list(known_facts)\n",
        "\n",
        "print(\"‚úÖ –õ–æ–≥–∏—á–µ—Å–∫–∏–π –¥–≤–∏–∂–æ–∫ –∑–∞–≥—Ä—É–∂–µ–Ω!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –¥–≤–∏–∂–∫–∞\n",
        "rule_data = read_rules(\"rules.json\")\n",
        "fact_data = read_facts(\"facts.json\")\n",
        "\n",
        "print(\"üìã –ò—Å—Ö–æ–¥–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞:\")\n",
        "for i, rule in enumerate(rule_data, 1):\n",
        "    print(f\"  {i}. {rule}\")\n",
        "\n",
        "print(f\"\\nüìä –ò—Å—Ö–æ–¥–Ω—ã–µ —Ñ–∞–∫—Ç—ã: {fact_data}\")\n",
        "\n",
        "# –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø—Ä–∞–≤–∏–ª–∞\n",
        "final_result = process_rules(rule_data, fact_data)\n",
        "\n",
        "print(f\"\\nüéØ –†–µ–∑—É–ª—å—Ç–∞—Ç –ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –≤—ã–≤–æ–¥–∞: {sorted(final_result)}\")\n",
        "print(f\"‚ú® –ù–æ–≤—ã–µ —Ñ–∞–∫—Ç—ã: {sorted(set(final_result) - set(fact_data))}\")\n",
        "\n",
        "# –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –ª–æ–≥–∏–∫–∏\n",
        "print(\"\\nüß† –õ–æ–≥–∏–∫–∞ –≤—ã–≤–æ–¥–∞:\")\n",
        "print(\"  1. –§–∞–∫—Ç 1 –ò–õ–ò 2 ‚Üí –≤—ã–≤–æ–¥–∏–º 10 (–ø—Ä–∞–≤–∏–ª–æ 1)\")\n",
        "print(\"  2. –ù–ï 10 –ò –ù–ï 11 ‚Üí –ù–ï –≤—ã–ø–æ–ª–Ω–µ–Ω–æ (–µ—Å—Ç—å —Ñ–∞–∫—Ç 10)\")\n",
        "print(\"  3. –ù–ï 15 –ò –ù–ï 16 ‚Üí –≤—ã–≤–æ–¥–∏–º 50 (–Ω–µ—Ç —Ñ–∞–∫—Ç–æ–≤ 15,16)\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
