{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# üî¢ TIOI PZ2: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ü–∏—Ñ—Ä MNIST (—á—ë—Ç/–Ω–µ—á—ë—Ç)\n",
        "\n",
        "–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Å–∏—Å—Ç–µ–º–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —á—ë—Ç–Ω–æ—Å—Ç–∏ —Ü–∏—Ñ—Ä –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ MNIST.\n",
        "\n",
        "**–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**\n",
        "- üß† –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –∏ –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è\n",
        "- üìä MLflow –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤  \n",
        "- üé® –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ —Ä–∏—Å–æ–≤–∞–Ω–∏–µ —Ü–∏—Ñ—Ä\n",
        "- üìà –î–µ—Ç–∞–ª—å–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
        "- üî¢ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Å–æ—Å—Ç–∞–≤–Ω—ã—Ö —Ü–∏—Ñ—Ä (–¥–≤—É—Ö–∑–Ω–∞—á–Ω—ã–µ —á–∏—Å–ª–∞)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install matplotlib numpy scikit-learn mlflow seaborn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ò–º–ø–æ—Ä—Ç—ã –∏ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import mlflow\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1.0 / (1.0 + np.exp(-np.clip(z, -250, 250)))\n",
        "\n",
        "def accuracy(pred, y):\n",
        "    return (pred == y).mean()\n",
        "\n",
        "def even_odd_labels(y_digit):\n",
        "    \"\"\"–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ü–∏—Ñ—Ä—ã –≤ –º–µ—Ç–∫–∏ —á—ë—Ç/–Ω–µ—á—ë—Ç\"\"\"\n",
        "    return (y_digit.astype(int) % 2).reshape(-1, 1)\n",
        "\n",
        "def load_mnist_even_odd(test_size=0.2, seed=42):\n",
        "    \"\"\"–ó–∞–≥—Ä—É–∂–∞–µ—Ç MNIST –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≤ –∑–∞–¥–∞—á—É —á—ë—Ç/–Ω–µ—á—ë—Ç\"\"\"\n",
        "    print(\"‚Üí –ó–∞–≥—Ä—É–∂–∞—é MNIST...\")\n",
        "    mnist = fetch_openml('mnist_784', parser='auto')\n",
        "    X = mnist['data'].to_numpy().astype(np.float32) / 255.0\n",
        "    y_digits = mnist['target'].to_numpy().astype(int)\n",
        "    \n",
        "    y = even_odd_labels(y_digits)\n",
        "    X_train, X_test, y_train, y_test, _, y_digits_test = train_test_split(\n",
        "        X, y, y_digits, test_size=test_size, random_state=seed, stratify=y)\n",
        "    \n",
        "    print(f\"  Train: {len(X_train)}, Test: {len(X_test)}\")\n",
        "    return X_train, X_test, y_train, y_test, y_digits_test\n",
        "\n",
        "print(\"‚úÖ –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ú–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, n_in, n_hidden, lam=1e-4, seed=0):\n",
        "        rng = np.random.default_rng(seed)\n",
        "        self.params = {\n",
        "            \"W1\": rng.normal(0, np.sqrt(2/n_in), size=(n_in, n_hidden)),\n",
        "            \"b1\": np.zeros((1, n_hidden)),\n",
        "            \"W2\": rng.normal(0, np.sqrt(2/n_hidden), size=(n_hidden, 1)),\n",
        "            \"b2\": np.zeros((1, 1))\n",
        "        }\n",
        "        self.lam = lam\n",
        "    \n",
        "    def _forward(self, X):\n",
        "        z1 = X @ self.params[\"W1\"] + self.params[\"b1\"]\n",
        "        a1 = sigmoid(z1)\n",
        "        z2 = a1 @ self.params[\"W2\"] + self.params[\"b2\"]\n",
        "        a2 = sigmoid(z2)\n",
        "        return a2, (X, z1, a1, z2, a2)\n",
        "    \n",
        "    def _backward(self, cache, y):\n",
        "        X, z1, a1, z2, a2 = cache\n",
        "        m = len(X)\n",
        "        dz2 = a2 - y\n",
        "        dW2 = a1.T @ dz2 / m + self.lam * self.params[\"W2\"]\n",
        "        db2 = dz2.mean(axis=0, keepdims=True)\n",
        "        dz1 = (dz2 @ self.params[\"W2\"].T) * a1 * (1 - a1)\n",
        "        dW1 = X.T @ dz1 / m + self.lam * self.params[\"W1\"]\n",
        "        db1 = dz1.mean(axis=0, keepdims=True)\n",
        "        return {\"W1\": dW1, \"b1\": db1, \"W2\": dW2, \"b2\": db2}\n",
        "    \n",
        "    def grads(self, X, y):\n",
        "        a2, cache = self._forward(X)\n",
        "        return self._backward(cache, y)\n",
        "    \n",
        "    def predict(self, X, batch=1024):\n",
        "        out = []\n",
        "        for i in range(0, len(X), batch):\n",
        "            a2, _ = self._forward(X[i:i+batch])\n",
        "            out.append(a2)\n",
        "        return (np.vstack(out) >= 0.5).astype(int)\n",
        "\n",
        "class GradientDescent:\n",
        "    def __init__(self, lr=0.1):\n",
        "        self.lr = lr\n",
        "    \n",
        "    def step(self, params, grads):\n",
        "        for k in params:\n",
        "            params[k] -= self.lr * grads[k]\n",
        "\n",
        "print(\"‚úÖ –ú–æ–¥–µ–ª–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
        "print(\"üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ MNIST...\")\n",
        "X_train, X_test, y_train, y_test, y_digits_test = load_mnist_even_odd()\n",
        "\n",
        "# –°–æ–∑–¥–∞—ë–º –º–æ–¥–µ–ª—å\n",
        "model = NeuralNetwork(X_train.shape[1], 64, lam=1e-4)\n",
        "optimizer = GradientDescent(lr=0.5)\n",
        "\n",
        "# –û–±—É—á–µ–Ω–∏–µ\n",
        "epochs = 20\n",
        "batch_size = 256\n",
        "print(f\"üß† –û–±—É—á–∞–µ–º –Ω–µ–π—Ä–æ—Å–µ—Ç—å ({epochs} —ç–ø–æ—Ö)...\")\n",
        "\n",
        "history = {\"train_acc\": [], \"test_acc\": []}\n",
        "idx = np.arange(len(X_train))\n",
        "\n",
        "for ep in range(1, epochs+1):\n",
        "    np.random.shuffle(idx)\n",
        "    for start in range(0, len(X_train), batch_size):\n",
        "        b = idx[start:start+batch_size]\n",
        "        grads = model.grads(X_train[b], y_train[b])\n",
        "        optimizer.step(model.params, grads)\n",
        "    \n",
        "    if ep % 5 == 0 or ep == epochs:\n",
        "        train_acc = accuracy(model.predict(X_train), y_train)\n",
        "        test_acc = accuracy(model.predict(X_test), y_test)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "        history[\"test_acc\"].append(test_acc)\n",
        "        print(f\"–≠–ø–æ—Ö–∞ {ep:2d}: train {train_acc:.3f}, test {test_acc:.3f}\")\n",
        "\n",
        "print(\"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# –ì—Ä–∞—Ñ–∏–∫ —Ç–æ—á–Ω–æ—Å—Ç–∏\n",
        "epochs_shown = [5, 10, 15, 20]\n",
        "ax1.plot(epochs_shown, history[\"train_acc\"], 'bo-', label='–û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞')\n",
        "ax1.plot(epochs_shown, history[\"test_acc\"], 'ro-', label='–¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞')\n",
        "ax1.set_xlabel('–≠–ø–æ—Ö–∞')\n",
        "ax1.set_ylabel('–¢–æ—á–Ω–æ—Å—Ç—å')\n",
        "ax1.set_title('–¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Confusion Matrix\n",
        "y_pred = model.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
        "           xticklabels=[\"–ß—ë—Ç–Ω–∞—è\", \"–ù–µ—á—ë—Ç–Ω–∞—è\"], \n",
        "           yticklabels=[\"–ß—ë—Ç–Ω–∞—è\", \"–ù–µ—á—ë—Ç–Ω–∞—è\"], ax=ax2)\n",
        "ax2.set_title('–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫')\n",
        "ax2.set_xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –º–µ—Ç–∫–∏')\n",
        "ax2.set_ylabel('–ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n",
        "final_accuracy = accuracy(y_pred, y_test)\n",
        "print(f\"\\nüéØ –§–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:\")\n",
        "print(f\"   –¢–æ—á–Ω–æ—Å—Ç—å: {final_accuracy:.4f}\")\n",
        "print(f\"   –ß—ë—Ç–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª—å–Ω–æ: {cm[0,0]}/{cm[0,0]+cm[0,1]}\")\n",
        "print(f\"   –ù–µ—á—ë—Ç–Ω—ã—Ö –ø—Ä–∞–≤–∏–ª—å–Ω–æ: {cm[1,1]}/{cm[1,0]+cm[1,1]}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
